{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01bde77-c306-4a12-bd85-42ffd97d03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Applies simplet5 setup, but uses a KNN classifier.\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from coprover import RSC_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881ea23e-cd7b-419d-a8f0-62431658e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MLM = False\n",
    "\n",
    "# Command prefixes are always expected\n",
    "CMD1_PREFIX = \"command1: \"\n",
    "\n",
    "SRC_TXT = 'source_text'\n",
    "TGT_TXT = 'target_text'\n",
    "CMD_HIST = 'cmd_history'\n",
    "BRANCH = 'branch'\n",
    "DEPTH = 'depth'\n",
    "\n",
    "# DATA_FPATH = Path(RSC_ROOT, \"pvs_cmd_pred\", \"data\", \"cmdpred_N3.prelude.tsv.gz\")\n",
    "DATA_FPATH = Path(RSC_ROOT, \"pvs_cmd_pred\", \"data\", \"cmdpred_N3.pvslib.tsv.gz\")\n",
    "\n",
    "full_df = pd.read_csv(DATA_FPATH,\n",
    "                      sep=\"\\t\",\n",
    "                      header=None,\n",
    "                      names=[SRC_TXT,\n",
    "                             TGT_TXT,\n",
    "                             CMD_HIST,\n",
    "                             BRANCH,\n",
    "                             DEPTH])\n",
    "\n",
    "# Use full command history, with cmdhist as a single tok \n",
    "# full_df['source_text'] = CMD1_PREFIX + full_df[CMD_HIST].replace(\",\", \"\") + \" <pad> \" + full_df[SRC_TXT]\n",
    "\n",
    "# Try without command history\n",
    "# full_df['source_text'] = CMD1_PREFIX  + \" <pad> \" + full_df[SRC_TXT]\n",
    "\n",
    "train_df, test_df = train_test_split(full_df, test_size=0.1,\n",
    "                                     random_state=1337,\n",
    "                                     shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7062ffde-5d19-484f-99fc-d169813eb6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>cmd_history</th>\n",
       "      <th>branch</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108441</th>\n",
       "      <td>&lt;ANT&gt; s-formula apply constant apply apply con...</td>\n",
       "      <td>expand1*</td>\n",
       "      <td>expand,skosimp*,expand</td>\n",
       "      <td>well_ordering-proofs/well_ordering#133</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51512</th>\n",
       "      <td>&lt;ANT&gt; s-formula apply constant apply constant ...</td>\n",
       "      <td>simplify</td>\n",
       "      <td>flatten,lemma,split</td>\n",
       "      <td>sigma_countable-proofs/sigma_disjoint_union#709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145976</th>\n",
       "      <td>&lt;ANT&gt; &lt;CONS&gt; s-formula exists ['variable'] app...</td>\n",
       "      <td>typepred</td>\n",
       "      <td>inst,expand,skosimp*</td>\n",
       "      <td>finite_sets_aux-proofs/is_finite_exists_N#10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91651</th>\n",
       "      <td>&lt;ANT&gt; s-formula apply constant apply constant ...</td>\n",
       "      <td>simplify</td>\n",
       "      <td>hide,lemma,inst</td>\n",
       "      <td>sigma-proofs/sigma_eq_one_arg#10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71902</th>\n",
       "      <td>&lt;ANT&gt; s-formula apply constant apply constant ...</td>\n",
       "      <td>label</td>\n",
       "      <td>skeep,label,label</td>\n",
       "      <td>convex_functions-proofs/convex_btw_pt_left_lt#4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71538</th>\n",
       "      <td>&lt;ANT&gt; s-formula apply constant forall ['variab...</td>\n",
       "      <td>inst</td>\n",
       "      <td>split,prop,lemma</td>\n",
       "      <td>sqrt_exists-proofs/sqrt_exists#81</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153946</th>\n",
       "      <td>&lt;ANT&gt; &lt;CONS&gt; s-formula forall ['variable'] ['v...</td>\n",
       "      <td>skosimp*</td>\n",
       "      <td>NOOP,NOOP,NOOP</td>\n",
       "      <td>integral_split_scaf-proofs/integral_F2_F1_TCC5#0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117415</th>\n",
       "      <td>&lt;ANT&gt; s-formula apply constant apply constant ...</td>\n",
       "      <td>flatten</td>\n",
       "      <td>hide,typepred,flatten-disjunct</td>\n",
       "      <td>max_fseq-proofs/max_seq_2#25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9448</th>\n",
       "      <td>&lt;ANT&gt; s-formula apply constant apply constant ...</td>\n",
       "      <td>rewrite</td>\n",
       "      <td>lemma,rewrite,lemma</td>\n",
       "      <td>trackAngles_2D-proofs/track_nx#28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>&lt;ANT&gt; s-formula apply constant apply constant ...</td>\n",
       "      <td>hide</td>\n",
       "      <td>hide,hide-all-but,cross-mult</td>\n",
       "      <td>vect2_cont_dot-proofs/scal_cont_rv#85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165901 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source_text target_text  \\\n",
       "108441  <ANT> s-formula apply constant apply apply con...    expand1*   \n",
       "51512   <ANT> s-formula apply constant apply constant ...    simplify   \n",
       "145976  <ANT> <CONS> s-formula exists ['variable'] app...    typepred   \n",
       "91651   <ANT> s-formula apply constant apply constant ...    simplify   \n",
       "71902   <ANT> s-formula apply constant apply constant ...       label   \n",
       "...                                                   ...         ...   \n",
       "71538   <ANT> s-formula apply constant forall ['variab...        inst   \n",
       "153946  <ANT> <CONS> s-formula forall ['variable'] ['v...    skosimp*   \n",
       "117415  <ANT> s-formula apply constant apply constant ...     flatten   \n",
       "9448    <ANT> s-formula apply constant apply constant ...     rewrite   \n",
       "3223    <ANT> s-formula apply constant apply constant ...        hide   \n",
       "\n",
       "                           cmd_history  \\\n",
       "108441          expand,skosimp*,expand   \n",
       "51512              flatten,lemma,split   \n",
       "145976            inst,expand,skosimp*   \n",
       "91651                  hide,lemma,inst   \n",
       "71902                skeep,label,label   \n",
       "...                                ...   \n",
       "71538                 split,prop,lemma   \n",
       "153946                  NOOP,NOOP,NOOP   \n",
       "117415  hide,typepred,flatten-disjunct   \n",
       "9448               lemma,rewrite,lemma   \n",
       "3223      hide,hide-all-but,cross-mult   \n",
       "\n",
       "                                                  branch  depth  \n",
       "108441            well_ordering-proofs/well_ordering#133    NaN  \n",
       "51512    sigma_countable-proofs/sigma_disjoint_union#709    NaN  \n",
       "145976      finite_sets_aux-proofs/is_finite_exists_N#10    NaN  \n",
       "91651                   sigma-proofs/sigma_eq_one_arg#10    NaN  \n",
       "71902    convex_functions-proofs/convex_btw_pt_left_lt#4    NaN  \n",
       "...                                                  ...    ...  \n",
       "71538                  sqrt_exists-proofs/sqrt_exists#81    NaN  \n",
       "153946  integral_split_scaf-proofs/integral_F2_F1_TCC5#0    NaN  \n",
       "117415                      max_fseq-proofs/max_seq_2#25    NaN  \n",
       "9448                   trackAngles_2D-proofs/track_nx#28    NaN  \n",
       "3223               vect2_cont_dot-proofs/scal_cont_rv#85    NaN  \n",
       "\n",
       "[165901 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba7ac55-e8fc-4cac-8220-177180dc8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = []\n",
    "train_targets = []\n",
    "for row in train_df.iterrows():\n",
    "    src_txt = row[1][SRC_TXT]\n",
    "    cmd = row[1][TGT_TXT]\n",
    "    train_corpus.append(src_txt)\n",
    "    train_targets.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b344cf1-bce7-4e67-bbf0-6f09b278c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = []\n",
    "test_targets = []\n",
    "for row in test_df.iterrows():\n",
    "    src_txt = row[1][SRC_TXT]\n",
    "    cmd = row[1][TGT_TXT]\n",
    "    test_corpus.append(src_txt)\n",
    "    test_targets.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e7e8aa5-d360-46e0-8fac-8fb3d210bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import collections\n",
    "\n",
    "src_txt_vectorizer = TfidfVectorizer(stop_words=None)\n",
    "label_lookup = collections.OrderedDict()\n",
    "\n",
    "def transform_labels(targets):\n",
    "    # CountVectorizer returns a one-hot.  This converts it into an integer\n",
    "    # array instead.\n",
    "    raw_Y = label_vectorizer.transform(targets).toarray()\n",
    "    return np.where(raw_Y > 0)[1]\n",
    "\n",
    "train_X = src_txt_vectorizer.fit_transform(train_corpus).toarray()\n",
    "test_X = src_txt_vectorizer.transform(test_corpus).toarray()\n",
    "\n",
    "# Combine train and test targets, so we get full coverage of labels\n",
    "for target in train_targets + test_targets:\n",
    "    if target not in label_lookup:\n",
    "        label_lookup[target] = len(label_lookup)\n",
    "\n",
    "def transform_labels(targets):\n",
    "    Y = np.array([label_lookup[target] for target in targets])\n",
    "    return Y\n",
    "\n",
    "train_Y = transform_labels(train_targets)\n",
    "test_Y = transform_labels(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b10407-411d-4759-9289-771ba006c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(train_targets)):\n",
    "    label = train_targets[idx]\n",
    "    label_id = train_Y[idx]\n",
    "    assert(label_lookup[label] == label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e714f724-3332-45da-89a7-062d4f9eaf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def get_acc(Y, Yhat):\n",
    "    acc = np.sum(Y == Yhat) / len(Y)\n",
    "    return acc\n",
    "    \n",
    "def assess(Y, Yhat):\n",
    "    acc = np.sum(Y == Yhat) / len(Y)\n",
    "    print(\"Acc = {:.5f}\".format(acc))\n",
    "    print(classification_report(Y, Yhat))\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00bf524-e65a-4e11-8ad9-addb746ef1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel='poly', random_state=0, tol=1e-5))\n",
    "clf.fit(train_X, train_Y)\n",
    "train_Yhat = clf.predict(train_X)\n",
    "test_Yhat = clf.predict(test_X)\n",
    "\n",
    "print(\"- - - - -\\n SVC Poly\")\n",
    "print(\"Training\")\n",
    "assess(train_Y, train_Yhat)\n",
    "\n",
    "print(\"Test\")\n",
    "assess(test_Y, test_Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fc7518-fe5f-4f2d-a6d6-f4b42931583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', random_state=0, tol=1e-5))\n",
    "clf.fit(train_X, train_Y)\n",
    "train_Yhat = clf.predict(train_X)\n",
    "test_Yhat = clf.predict(test_X)\n",
    "\n",
    "print(\"- - - - -\\n SVC RBF\")\n",
    "print(\"Training\")\n",
    "assess(train_Y, train_Yhat)\n",
    "\n",
    "print(\"Test\")\n",
    "assess(test_Y, test_Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df097ac8-8197-430d-bb8d-a6e0b7194185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), LinearSVC(random_state=0, tol=1e-5))\n",
    "clf.fit(train_X, train_Y)\n",
    "train_Yhat = clf.predict(train_X)\n",
    "test_Yhat = clf.predict(test_X)\n",
    "\n",
    "print(\"- - - - -\\n LinearSVC\")\n",
    "print(\"Training\")\n",
    "assess(train_Y, train_Yhat)\n",
    "\n",
    "print(\"Test\")\n",
    "assess(test_Y, test_Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d5709-35d5-4191-ac51-e33f7939a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "for N in range(1,11):\n",
    "    knn_clf = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=N))\n",
    "    knn_clf.fit(train_X, train_Y)\n",
    "    train_Yhat = knn_clf.predict(train_X)\n",
    "    test_Yhat = knn_clf.predict(test_X)\n",
    "\n",
    "    print(\"- - - - -\\nkNN N={}\".format(N))\n",
    "    print(\"Training\")\n",
    "    print(\"{:.5f}\".format(get_acc(train_Y, train_Yhat)))\n",
    "\n",
    "    print(\"Test\")\n",
    "    print(\"{:.5f}\".format(get_acc(test_Y, test_Yhat)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coprovers] *",
   "language": "python",
   "name": "conda-env-coprovers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
