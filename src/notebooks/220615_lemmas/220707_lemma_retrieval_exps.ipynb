{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3ef4c5-ed91-4507-a379-65f4f880db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372109de-c4ce-4c30-ae13-f4e87a9c5b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766 9206\n",
      "Lemma queries cached, loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 766/766 [00:02<00:00, 283.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train=12132, test=8089, total=20221\n",
      "10000/100000\n",
      "20000/100000\n",
      "30000/100000\n",
      "40000/100000\n",
      "50000/100000\n",
      "60000/100000\n",
      "70000/100000\n",
      "80000/100000\n",
      "90000/100000\n",
      "100000/100000\n",
      "10/100\n",
      "20/100\n",
      "30/100\n",
      "40/100\n",
      "50/100\n",
      "60/100\n",
      "70/100\n",
      "80/100\n",
      "90/100\n",
      "100/100\n"
     ]
    }
   ],
   "source": [
    "from setup_queries import *\n",
    "from coprover.utils import ensure_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303e2eed-c9fd-4c72-a0cc-21cb592572cf",
   "metadata": {},
   "source": [
    "Similar to the first lemma retrieval experiment, but we now use a CountVectorizer and TfidfVectorizer to properly convert everything into vectors.\n",
    "\n",
    "We take in $N lemma requests from the command history.  A lemma request is a PVS *lemma* command where the first argument is the lemma name to import.  We take these from the command history for each of the proofs.\n",
    "\n",
    "In order to simplify the problem, we pool all of the possible lemmas from all theories and consider them all as candidates.  Future iterations of this experiment will consider restricting the set of considered lemmas to be just the ones available in the theory the proof was derived for in PVSLib.\n",
    "\n",
    "Another todo is to incorporate the PVS Prelude, as that is a mutually exclusive set of theories and proofs.\n",
    "\n",
    "To faciliate comparisons against supervised methods, we separate the lemma queries into train and test sets, randomly shuffled and partitioned at a 60/40 train/test split.  From an original set of 20221 viable lemma queries, we get a train/test split size of 12132/8089.\n",
    "\n",
    "Corpus level statistics (TFIDF, counts) were computed over the theories in the TheoryBank.\n",
    "\n",
    "\n",
    "----\n",
    "Comparing TFIDF vs Unigram counts\n",
    "\n",
    "We use the mean reciprocal rank (MRR) for each vectorization strategy, along with whether 1-norm was applied or not.  Here, TFIDF without normalization was the clear winner.\n",
    "\n",
    "Count Norm: MRR=0.00126\n",
    "TFIDF Norm: MRR=0.00126\n",
    "Count NoNorm: MRR=0.00316\n",
    "TFIDF NoNorm: MRR=0.08397\n",
    "\n",
    "---- \n",
    "Running a SVC.  Note that this uses accuracy, and is not in a reranking form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f107b-75a5-44a0-b466-5febe8c7512e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import JSON\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from enum import Enum\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import thundersvm\n",
    "\n",
    "from coprover import PROJ_ROOT, RSC_ROOT, PVSLIB_ROOT\n",
    "from featurizer import *\n",
    "\n",
    "DATA_ROOT = Path(PROJ_ROOT, \"data\", \"pvs\", \"pvslib\")\n",
    "json_files = list(DATA_ROOT.rglob(\"*.json\"))\n",
    "\n",
    "theory_files = list(DATA_ROOT.glob(\"*/*.json\"))\n",
    "proof_files = list(DATA_ROOT.glob(\"*/*/*.json\"))\n",
    "print(len(theory_files), len(proof_files))\n",
    "\n",
    "import pdb\n",
    "\n",
    "class VecTypes:\n",
    "    COUNT = 1\n",
    "    TFIDF = 2\n",
    "\n",
    "class TheoryBank:\n",
    "    def __init__(self, theory_files, \n",
    "                 vectorizer_type=VecTypes.COUNT,\n",
    "                 norm_vecs=True):\n",
    "        self.all_theories = collections.OrderedDict()\n",
    "        self.all_lemmas = collections.OrderedDict()\n",
    "        for json_fpath in tqdm(theory_files):\n",
    "            with open(json_fpath, 'r') as f:\n",
    "                theory_name = json_fpath.stem\n",
    "                doc_root = json.load(f)\n",
    "                theory = read_theory(doc_root)\n",
    "                self.all_theories[theory_name] = theory\n",
    "                self.all_lemmas.update(theory)\n",
    "        corpus = [\" \".join([str(y) for y in x]) for x in self.all_lemmas.values()]\n",
    "        self.names = list(self.all_lemmas.keys())\n",
    "        if vectorizer_type == VecTypes.COUNT:\n",
    "            self.vectorizer = CountVectorizer(stop_words=None, lowercase=False)\n",
    "        elif vectorizer_type == VecTypes.TFIDF:\n",
    "            self.vectorizer = TfidfVectorizer(stop_words=None, lowercase=False)\n",
    "        self.M = self.vectorizer.fit_transform(corpus).toarray()\n",
    "        # 1-norm\n",
    "        self.norm_vecs = norm_vecs\n",
    "        if self.norm_vecs:\n",
    "            self.M = self.M / np.linalg.norm(self.M, axis=1).reshape((self.M.shape[0], 1))\n",
    "        \n",
    "    def contains(self, name):\n",
    "        return name in self.names\n",
    "        \n",
    "    def query(self, qdocs, top_N=5):\n",
    "        \"\"\"\n",
    "        Expects a list of lists (docs x toks)\n",
    "        \"\"\"\n",
    "        q = self.vectorizer.transform(qdocs).toarray()\n",
    "        if self.norm_vecs:\n",
    "            q = q / np.linalg.norm(q, axis=0)\n",
    "        num_queries = len(qdocs)\n",
    "        S = self.M.dot(q.transpose())\n",
    "        sorted_idxes = np.argsort(S, axis=0)\n",
    "        if top_N is None:\n",
    "            max_idxes = sorted_idxes\n",
    "        else:\n",
    "            max_idxes = sorted_idxes[-top_N:, :]\n",
    "        \n",
    "        # Assemble list of names\n",
    "        titles = []\n",
    "        for qnum in range(len(qdocs)):\n",
    "            titles.append([self.names[idx] for idx in max_idxes[::-1, qnum]])\n",
    "        return titles\n",
    "    \n",
    "    def get(self, name, theories=None):\n",
    "        if theories is None:\n",
    "            theories = sorted(self.all_theories.keys())\n",
    "        for theory in theories:\n",
    "            if name in self.all_theories[theory]:\n",
    "                return self.all_theories[theory][name], theory\n",
    "        return None, None\n",
    "        # raise Exception(\"Could not identify name={} in theory set={}\".format(name, theories))\n",
    "    \n",
    "    def sample(self, rand_obj=None):\n",
    "        if rand_obj is None:\n",
    "            return np.random.choice(list(self.all_lemmas.values()))\n",
    "        else:\n",
    "            return rand_obj.choice(list(self.all_lemmas.values()))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17741eaa-66ad-4d31-9cf3-379c795a1153",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "theory_bank = TheoryBank(theory_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4abf5c1-821e-450f-9f6c-121291a6f2d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Now go through each of the proofs and collect the lemma requests\n",
    "\n",
    "LEMMA_OUTPUT_FPATH = Path(\"lemma_requests.json\")\n",
    "NAME = \"name\"\n",
    "STEP = \"step\"\n",
    "STATE = \"state\"\n",
    "CMD = \"command\"\n",
    "ARGS = \"args\"\n",
    "\n",
    "if LEMMA_OUTPUT_FPATH.exists():\n",
    "    # Load the lemma queries\n",
    "    print(\"Lemma queries cached, loading\")\n",
    "    with open(LEMMA_OUTPUT_FPATH, 'r') as f:\n",
    "        lemma_requests = json.load(f)\n",
    "else:\n",
    "    # Accumulate the lemma retrieval queries\n",
    "    tqdm_iter = tqdm(proof_files)\n",
    "    num_lemma_requests = 0\n",
    "    lemma_requests = []\n",
    "\n",
    "\n",
    "    for json_fpath in tqdm_iter:\n",
    "        name = Path(json_fpath).stem\n",
    "        sa_tuples = read_proof_session_lemmas(json_fpath)\n",
    "        if sa_tuples is None:\n",
    "            continue\n",
    "        for step_num, sa_tuple in enumerate(sa_tuples):\n",
    "            cmd, arg = sa_tuple[1], sa_tuple[2]\n",
    "            if arg is not None and isinstance(arg, str):\n",
    "                arg = arg.split(\"[\")[0]\n",
    "                if cmd in set([\"lemma\", \"rewrite\"]):\n",
    "                    # expr, theory = theory_bank.get(arg)\n",
    "                    num_lemma_requests += 1\n",
    "                    lemma_requests.append({\n",
    "                        STATE:  sa_tuple[0],\n",
    "                        CMD: cmd,\n",
    "                        ARGS: arg,\n",
    "                        NAME: name,\n",
    "                        STEP: step_num\n",
    "                    })\n",
    "                    tqdm_iter.set_description(\"# lemma requests={}\".format(num_lemma_requests))\n",
    "\n",
    "    # Save out the accumulated lemma requests to file                \n",
    "    with open(LEMMA_OUTPUT_FPATH, 'w') as f:\n",
    "        json.dump(lemma_requests, f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4ae0c-7e41-463f-b055-b0d24c81c37e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Split into train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "lemma_train, lemma_test = train_test_split(\n",
    "     lemma_requests, train_size=0.6, random_state=1337, shuffle=True, stratify=None)\n",
    "print(\"# train={}, test={}, total={}\".format(len(lemma_train), len(lemma_test), len(lemma_requests)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fecf4bce-e1dd-43d0-aa7d-f9303c94d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize a query\n",
    "def make_statestr(state, consequents_only=False):\n",
    "    \"\"\" Given lemma state, converts into query string usable for theory bank\"\"\"\n",
    "    collecting = not(consequents_only)\n",
    "    toks = []\n",
    "    for tok in state:\n",
    "        if tok == \"consequents\":\n",
    "            collecting = True\n",
    "        elif collecting:\n",
    "            toks.append(str(tok))\n",
    "    return \" \".join(toks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c028dd86-969e-46f8-896e-3a82a99fcf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 766/766 [00:03<00:00, 254.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 766/766 [00:02<00:00, 304.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 766/766 [00:02<00:00, 305.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 766/766 [00:02<00:00, 304.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from theorybank import TheoryBank, theory_files, VecTypes\n",
    "# Make several theory banks\n",
    "count_tb_nonorm = TheoryBank(theory_files, vectorizer_type=VecTypes.COUNT, norm_vecs=False)\n",
    "tfidf_tb_nonorm = TheoryBank(theory_files, vectorizer_type=VecTypes.TFIDF, norm_vecs=False)\n",
    "count_tb_norm = TheoryBank(theory_files, vectorizer_type=VecTypes.COUNT, norm_vecs=True)\n",
    "tfidf_tb_norm = TheoryBank(theory_files, vectorizer_type=VecTypes.TFIDF, norm_vecs=True)\n",
    "\n",
    "experiments = ( (\"Count_NoNorm\", count_tb_nonorm), (\"TFIDF_NoNorm\", tfidf_tb_nonorm),\n",
    "              (\"Count_Norm\", count_tb_norm), (\"TFIDF_Norm\", tfidf_tb_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e9109b2-f193-4d50-bb90-50d11621ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurizer import NAME\n",
    "STATE=\"state\"\n",
    "def compute_mrr(theory_bank):\n",
    "    retrieval_ranks = []\n",
    "    for req in tqdm(test_queries):\n",
    "        gold = req[NAME]\n",
    "        if not(theory_bank.contains(gold)):\n",
    "            continue\n",
    "        state_str = make_statestr(req[STATE])\n",
    "        retrieved = theory_bank.query([state_str], top_N=None)\n",
    "        rank = retrieved[0].index(gold)\n",
    "        retrieval_ranks.append(rank)\n",
    "    mrr = np.mean([1/(rank + 1) for rank in retrieval_ranks])\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b9414fc-d75d-4da6-b81e-b239e01ed761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 8089/8089 [04:08<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count_NoNorm: MRR=0.00302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 8089/8089 [01:31<00:00, 88.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF_NoNorm: MRR=0.04312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 0/8089 [00:00<?, ?it/s]/home/fennel2/yeh/proj/CoProver/src/notebooks/220615_lemmas/theorybank.py:91: RuntimeWarning: invalid value encountered in true_divide\n",
      "  q = q / np.linalg.norm(q, axis=0)\n",
      "100%|████████████████████████████████████████████████████████████████████| 8089/8089 [01:22<00:00, 98.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count_Norm: MRR=0.00069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 8089/8089 [01:27<00:00, 92.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF_Norm: MRR=0.00069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for expname, theory_bank in experiments:\n",
    "    mrr = compute_mrr(theory_bank)\n",
    "    results[expname] = mrr\n",
    "    print(\"{}: MRR={:.5f}\".format(expname, mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0dc1f6-00c6-442b-85b5-27bae98692f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78cf4a41-1921-4d4b-a88a-71a96459b581",
   "metadata": {},
   "source": [
    "# Supervised experiment.  \n",
    "For each of the training items, set up a featurization that consists of q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dd49377-6146-4b42-a4b9-4d0c5abc7359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "import pdb\n",
    "np_rng = default_rng(505)\n",
    "\n",
    "def assemble_data(lemma_src, tb, limit=100):\n",
    "    \"\"\"\n",
    "    Get one positive, exact match\n",
    "    One easy negative, random sample\n",
    "    One hard negative, random sample that is close\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in tqdm(range(limit)):\n",
    "        req = lemma_src[i]\n",
    "        state_str = make_statestr(req[STATE])\n",
    "        q = tb.vectorizer.transform([state_str]).toarray()\n",
    "        gold_lemma = tb.get(req[NAME])\n",
    "        gold_x = tb.vectorizer.transform([make_statestr(gold_lemma)]).toarray()\n",
    "        random_x = tb.vectorizer.transform([make_statestr(tb.sample())]).toarray()      \n",
    "        x_pos = np.dot(q.transpose(), gold_x).ravel()\n",
    "        x_neg = np.dot(q.transpose(), random_x).ravel()\n",
    "        \n",
    "        # Get the hard negative\n",
    "        S = tb.M.dot(gold_x.transpose())\n",
    "        sorted_idxes = np.argsort(S, axis=0)\n",
    "        hard_neg_idx = np_rng.integers(low=1, high=len(sorted_idxes), size=1)[0]\n",
    "        x_hard_neg = np.dot(q.transpose(), tb.M[hard_neg_idx].reshape((1, -1))).ravel()\n",
    "        # pdb.set_trace()\n",
    "        X.append(x_pos)\n",
    "        X.append(x_neg)\n",
    "        X.append(x_hard_neg)\n",
    "        Y.append(1)\n",
    "        Y.append(-1)\n",
    "        Y.append(-1)        \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41f7c3-cbeb-4797-bbd9-9746a2f7340c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_11458/4227843498.py:93: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.random.choice(list(self.all_lemmas.values()))\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# import sklearn.svm as svm\n",
    "# Try ThunderSVM, GPU accelerated SVC\n",
    "#num_train = 1000\n",
    "num_train = 10\n",
    "num_test = 10\n",
    "\n",
    "svc_results = collections.OrderedDict()\n",
    "for expname, theory_bank in experiments:\n",
    "    # svc = svm.LinearSVC()\n",
    "    svc = thundersvm.SVC()\n",
    "    train_X, train_Y = assemble_data(lemma_train, theory_bank, num_train)\n",
    "    test_X, test_Y = assemble_data(lemma_test, theory_bank, num_test)\n",
    "    svc.fit(train_X, train_Y)\n",
    "    train_Yhat = svc.predict(train_X)\n",
    "    test_Yhat = svc.predict(test_X)\n",
    "    train_acc = np.sum(train_Yhat == train_Y) / train_X.shape[0]\n",
    "    test_acc = np.sum(test_Yhat == test_Y) / test_X.shape[0]\n",
    "    svc_results[expname] = {\n",
    "        \"train_acc\": train_acc,\n",
    "        \"test_acc\": test_acc\n",
    "    }\n",
    "    print(\"{}: train_acc={:.3f}, test_acc={:.3f}\".format(expname, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e7bd7-e947-4efe-a69c-40886b0a6500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coprovers] *",
   "language": "python",
   "name": "conda-env-coprovers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
