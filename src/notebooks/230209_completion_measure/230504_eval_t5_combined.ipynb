{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d13797-dd66-468d-9193-9ab266985c70",
   "metadata": {},
   "source": [
    "This evaluates the last command prediction model trained on both V1 and V2 of the data, around different combinations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c230c79-f211-454f-beb4-e65b1071e925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1337\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from exp_setup import *\n",
    "from coprover.results_analysis import GuessGoldTelemetry\n",
    "from coprover.training.simplet5 import SimpleT5\n",
    "\n",
    "MODELS_DIR = Path(\"outputs\")\n",
    "RESULTS_DIR = Path(\"results\", \"t5\", \"v1\")\n",
    "\n",
    "DEVICE = \"cuda:1\"\n",
    "\n",
    "# Model listing, tuple (strip_cmdhistory, cmds_only, path)\n",
    "MODELS = {\n",
    "    \"t5_full_v1\": (False, False, Path(MODELS_DIR, \"laststep_pred_v1\", \"best_model\")),\n",
    "    \"t5_cmdsonly_v1\": (False, True, Path(MODELS_DIR, \"laststep_pred_cmdsonly_v1\", \"best_model\")),\n",
    "    \"t5_nocmds_v1\": (True, False, Path(MODELS_DIR, \"laststep_pred_nocmds_v1\", \"best_model\"))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d71cc28-bae9-4090-9182-4376879e7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(exp_name, strip_cmdhistory, cmds_only, model_fpath):\n",
    "    print(f\"Running experiment: {exp_name}, model_fpath={model_fpath}, strip_cmdhistory={strip_cmdhistory}, cmds_only={cmds_only}\")\n",
    "    model = SimpleT5(source_max_token_len=SRC_MAX_TOKLEN, target_max_token_len=TGT_MAX_TOKLEN)\n",
    "    model.load_model(model_fpath, use_gpu=True, use_device=DEVICE)\n",
    "    train_df, test_df = setup_laststep_pred_data(strip_cmdhistory=strip_cmdhistory, cmds_only=cmds_only)\n",
    "    print(f\"Len train={len(train_df)}, test={len(test_df)}\")\n",
    "    print(f\"Train, # pos={np.sum(train_df.target_text == POS)}, neg={np.sum(train_df.target_text == NEG)}\")\n",
    "    print(f\"Test, # pos={np.sum(test_df.target_text == POS)}, neg={np.sum(test_df.target_text == NEG)}\")\n",
    "    \n",
    "    # Eval Test\n",
    "    test_Y_guess = []\n",
    "    test_Y_gold = test_df.target_text.array\n",
    "    for src_txt in tqdm(test_df.source_text.array):\n",
    "        test_Y_guess.append(model.predict(src_txt)[0])\n",
    "    test_telem = GuessGoldTelemetry(guesses=test_Y_guess, golds=test_Y_gold, target_names=[NEG, POS], \n",
    "                                    name=\"{exp_name} Test\")\n",
    "    RESULTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    test_telem.save(Path(RESULTS_DIR, f\"{exp_name}.csv\"))\n",
    "    print(\"Test Result\")\n",
    "    print(test_telem.class_report(return_dict=False))\n",
    "    # Subsample train\n",
    "    idx = 1000\n",
    "    train_Y_guess = []\n",
    "    train_Y_gold = train_df.target_text.array[0:idx]\n",
    "    for src_txt in tqdm(train_df.source_text.array[0:idx]):\n",
    "        train_Y_guess.append(model.predict(src_txt)[0])\n",
    "    train_telem = GuessGoldTelemetry(guesses=train_Y_guess, golds=train_Y_gold, target_names=[NEG, POS], \n",
    "                                     name=f\"{exp_name} Train(0:{idx})\")\n",
    "    print(\"Train Result\")\n",
    "    print(train_telem.class_report(return_dict=False))\n",
    "    return test_telem, train_telem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d948cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: t5_full_v1, model_fpath=outputs/laststep_pred_v1/best_model, strip_cmdhistory=False, cmds_only=False\n",
      "Loading model_type=t5, dir=outputs/laststep_pred_v1/best_model, use_gpu=True\n",
      "Len train=11162, test=1241\n",
      "Len train=11162, test=1241\n",
      "Train, # pos=5578, neg=5584\n",
      "Test, # pos=626, neg=615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1241 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1241/1241 [01:12<00:00, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.56      0.67       615\n",
      "         pos       0.67      0.88      0.76       626\n",
      "\n",
      "    accuracy                           0.72      1241\n",
      "   macro avg       0.75      0.72      0.71      1241\n",
      "weighted avg       0.75      0.72      0.71      1241\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:58<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.90      0.62      0.73       527\n",
      "         pos       0.69      0.92      0.79       473\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.79      0.77      0.76      1000\n",
      "weighted avg       0.80      0.76      0.76      1000\n",
      "\n",
      "Running experiment: t5_cmdsonly_v1, model_fpath=outputs/laststep_pred_cmdsonly_v1/best_model, strip_cmdhistory=False, cmds_only=True\n",
      "Loading model_type=t5, dir=outputs/laststep_pred_cmdsonly_v1/best_model, use_gpu=True\n",
      "Len train=11162, test=1241\n",
      "Len train=11162, test=1241\n",
      "Train, # pos=5578, neg=5584\n",
      "Test, # pos=626, neg=615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1241/1241 [00:54<00:00, 22.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.74      0.49      0.59       615\n",
      "         pos       0.62      0.83      0.71       626\n",
      "\n",
      "    accuracy                           0.66      1241\n",
      "   macro avg       0.68      0.66      0.65      1241\n",
      "weighted avg       0.68      0.66      0.65      1241\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:43<00:00, 22.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.83      0.53      0.65       527\n",
      "         pos       0.63      0.88      0.73       473\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.73      0.70      0.69      1000\n",
      "weighted avg       0.73      0.69      0.69      1000\n",
      "\n",
      "Running experiment: t5_nocmds_v1, model_fpath=outputs/laststep_pred_nocmds_v1/best_model, strip_cmdhistory=True, cmds_only=False\n",
      "Loading model_type=t5, dir=outputs/laststep_pred_nocmds_v1/best_model, use_gpu=True\n",
      "Len train=11162, test=1241\n",
      "Len train=11162, test=1241\n",
      "Train, # pos=5578, neg=5584\n",
      "Test, # pos=626, neg=615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1241 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1241/1241 [01:12<00:00, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.69      0.64      0.66       615\n",
      "         pos       0.67      0.71      0.69       626\n",
      "\n",
      "    accuracy                           0.68      1241\n",
      "   macro avg       0.68      0.68      0.68      1241\n",
      "weighted avg       0.68      0.68      0.68      1241\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:58<00:00, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.73      0.67      0.70       527\n",
      "         pos       0.66      0.72      0.69       473\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.70      0.69      0.69      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for exp_name, exp_tuple in MODELS.items():\n",
    "    strip_cmdhistory, cmds_only, model_fpath = exp_tuple\n",
    "    test_telem, train_telem = run_experiment(exp_name, strip_cmdhistory, cmds_only, model_fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coprovers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
